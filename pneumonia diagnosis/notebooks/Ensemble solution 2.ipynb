{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da34cd3e-fd91-49a8-a854-ae370a5a0dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3353f43-d5ad-4cc4-909f-0b4e8e659077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download dataset from Kaggle.\n",
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c7edc3-2b7a-427e-8c6c-9c8a9f9257c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Working on CPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms, models, datasets\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA is available. Working on GPU')\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    print('CUDA is not available. Working on CPU')\n",
    "    DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "866173bc-0fe6-42ef-9132-a72b04af95a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "SEED = 42 # \"Answer to the Ultimate Question of Life, the Universe, and Everything\"\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "root_dir = '../inputs/chest_xray'\n",
    "train_dir = root_dir + '/train'\n",
    "valid_dir = root_dir + '/val'\n",
    "test_dir  = root_dir + '/test'\n",
    "\n",
    "img_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b075f68-e6e1-4e4e-9b2d-860b644d091e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unused (actually used for plotting), better way found (marked as \"* better way\")\n",
    "def  generate_dataframes(root_dir):\n",
    "    train_df = pd.DataFrame(columns=['xray_dir', 'pneumonia (label)'])\n",
    "    test_df  = pd.DataFrame(columns=['xray_dir', 'pneumonia (label)'])\n",
    "    valid_df = pd.DataFrame(columns=['xray_dir', 'pneumonia (label)'])\n",
    "    \n",
    "    for dirname, _, filenames in os.walk(root_dir):     \n",
    "        \n",
    "        # Train\n",
    "        if dirname == root_dir + 'train/' + 'NORMAL':\n",
    "            for filename in filenames:\n",
    "                train_df.loc[len(train_df)] = [dirname + '/' + filename, 0]\n",
    "\n",
    "        elif dirname == root_dir + 'train/' + 'PNEUMONIA':\n",
    "            for filename in filenames:\n",
    "                train_df.loc[len(train_df)] = [dirname + '/' + filename, 1]\n",
    "        \n",
    "        # Test\n",
    "        if dirname == root_dir + 'test/' + 'NORMAL':\n",
    "            for filename in filenames:\n",
    "                test_df.loc[len(test_df)] = [dirname + '/' + filename, 0]\n",
    "\n",
    "        elif dirname == root_dir + 'test/' + 'PNEUMONIA':\n",
    "            for filename in filenames:\n",
    "                test_df.loc[len(test_df)] = [dirname + '/' + filename, 1]\n",
    "        \n",
    "        # Validation\n",
    "        if dirname == root_dir + 'val/' + 'NORMAL':\n",
    "            for filename in filenames:\n",
    "                valid_df.loc[len(valid_df)] = [dirname + '/' + filename, 0]\n",
    "\n",
    "        elif dirname == root_dir + 'val/' + 'PNEUMONIA':\n",
    "            for filename in filenames:\n",
    "                valid_df.loc[len(valid_df)] = [dirname + '/' + filename, 1]\n",
    "                \n",
    "    return train_df, test_df, valid_df\n",
    "\n",
    "train_df, test_df, valid_df = generate_dataframes('../inputs/chest_xray/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be8ac7cd-3631-44ee-9447-c2a6b7d3e7ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xray_dir</th>\n",
       "      <th>pneumonia (label)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../inputs/chest_xray/train/NORMAL/IM-0177-0001...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../inputs/chest_xray/train/NORMAL/IM-0761-0001...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            xray_dir  pneumonia (label)\n",
       "0  ../inputs/chest_xray/train/NORMAL/IM-0177-0001...                  0\n",
       "1  ../inputs/chest_xray/train/NORMAL/IM-0761-0001...                  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a50f7b2-bcf6-445d-a76d-8f8ff29d2602",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3875\n",
       "0    1341\n",
       "Name: pneumonia (label), dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = train_df['pneumonia (label)'].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "774b900c-ce2a-4d4c-847d-5628023cb379",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Pneumonia x Normal')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(counts.index, counts) \n",
    "plt.title('Pneumonia x Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92c42232-50a7-4cfb-88e0-bbfe2689faf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data, target, transform=None, device=device):\n",
    "        self.device = device\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index].to(self.device)\n",
    "        y = self.target[index].to(self.device)\n",
    "        \n",
    "        #if (y == 0) and self.transform: # check for minority class\n",
    "        x = self.transform(x)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "# num_classes = 2\n",
    "def unbalanced_dataset_weights(instances):\n",
    "    count = [0] * 2\n",
    "    for item in instances:\n",
    "        count[item[1]] += 1\n",
    "        \n",
    "    class_weight = [0.] * 2\n",
    "    total = float(sum(count))\n",
    "    \n",
    "    for i in range(2):\n",
    "        class_weight[i] = total/float(count[i])\n",
    "    \n",
    "    weight = [0] * len(instances)\n",
    "    \n",
    "    for index, value in enumerate(instances):\n",
    "        weight[index] = class_weight[value[1]]\n",
    "        \n",
    "    return weight\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((img_size, img_size)),\n",
    "                                transforms.RandomRotation(30),\n",
    "                                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "train_ds = datasets.ImageFolder(train_dir, transform)\n",
    "weights = unbalanced_dataset_weights(train_ds.imgs)\n",
    "weights = torch.tensor(weights, dtype=torch.double)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n",
    "train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, sampler= sampler)\n",
    "\n",
    "valid_ds = datasets.ImageFolder(valid_dir, transform)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_ds, batch_size=2, shuffle=False)\n",
    "\n",
    "test_ds = datasets.ImageFolder(test_dir, transform)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f70f2987-1155-4e9a-9f24-2ab6ed925ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training(model, model_name, num_epochs, train_dataloader, val_dataloader):\n",
    "\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.33)\n",
    "\n",
    "    train_loss_array = []\n",
    "    train_acc_array = []\n",
    "    val_loss_array = []\n",
    "    val_acc_array = []\n",
    "    lowest_val_loss = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "\n",
    "        print('Epoch: {} | Learning rate: {}'.format(epoch + 1, scheduler.get_lr()))\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "\n",
    "            epoch_loss = 0\n",
    "            epoch_correct_items = 0\n",
    "            epoch_items = 0\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                with torch.enable_grad():\n",
    "                    for samples, targets in tqdm(train_dataloader):\n",
    "                        samples = samples.to(DEVICE)\n",
    "                        targets = targets.to(DEVICE)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model(samples)\n",
    "                        loss = loss_function(outputs, targets)\n",
    "                        preds = outputs.argmax(dim=1)\n",
    "                        correct_items = (preds == targets).float().sum()\n",
    "                        \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        epoch_loss += loss.item()\n",
    "                        epoch_correct_items += correct_items.item()\n",
    "                        epoch_items += len(targets)\n",
    "                print(epoch_items)\n",
    "\n",
    "                train_loss_array.append(epoch_loss / epoch_items)\n",
    "                train_acc_array.append(epoch_correct_items / epoch_items)\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "            elif phase == 'val':\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for samples, targets in tqdm(val_dataloader):\n",
    "                        samples = samples.to(DEVICE)\n",
    "                        targets = targets.to(DEVICE)\n",
    "\n",
    "                        outputs = model(samples)\n",
    "                        loss = loss_function(outputs, targets)\n",
    "                        preds = outputs.argmax(dim=1)\n",
    "                        correct_items = (preds == targets).float().sum()\n",
    "\n",
    "                        epoch_loss += loss.item()\n",
    "                        epoch_correct_items += correct_items.item()\n",
    "                        epoch_items += len(targets)\n",
    "                print(epoch_items)\n",
    "\n",
    "                val_loss_array.append(epoch_loss / epoch_items)\n",
    "                val_acc_array.append(epoch_correct_items / epoch_items)\n",
    "\n",
    "                if epoch_loss / epoch_items < lowest_val_loss:\n",
    "                    lowest_val_loss = epoch_loss / epoch_items\n",
    "                    torch.save(model.state_dict(), '{}_weights.pth'.format(model_name))\n",
    "                    best_model = copy.deepcopy(model)\n",
    "                    print(\"\\t| New lowest val loss for {}: {}\".format(model_name, lowest_val_loss))\n",
    "\n",
    "    return best_model, train_loss_array, train_acc_array, val_loss_array, val_acc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85694fe5-a8d0-4c2d-bac1-dcf07cfd1816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_training_results(train_loss_array,\n",
    "                               val_loss_array,\n",
    "                               train_acc_array,\n",
    "                               val_acc_array,\n",
    "                               num_epochs,\n",
    "                               model_name,\n",
    "                               batch_size):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14,4))\n",
    "    fig.suptitle(\"{} training | Batch size: {}\".format(model_name, batch_size), fontsize = 16)\n",
    "    axs[0].plot(list(range(1, num_epochs+1)), train_loss_array, label=\"train_loss\")\n",
    "    axs[0].plot(list(range(1, num_epochs+1)), val_loss_array, label=\"val_loss\")\n",
    "    axs[0].legend(loc='best')\n",
    "    axs[0].set(xlabel='epochs', ylabel='loss')\n",
    "    axs[1].plot(list(range(1, num_epochs+1)), train_acc_array, label=\"train_acc\")\n",
    "    axs[1].plot(list(range(1, num_epochs+1)), val_acc_array, label=\"val_acc\")\n",
    "    axs[1].legend(loc='best')\n",
    "    axs[1].set(xlabel='epochs', ylabel='accuracy')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1a19af-d78d-48a1-a919-0cc00e4e33b6",
   "metadata": {},
   "source": [
    "## Train Densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b92ab55-1ef0-4000-bde8-40c6f993a674",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Learning rate: [0.0003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                   | 0/326 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▏                                          | 1/326 [00:03<18:16,  3.37s/it]\u001b[A\n",
      "  1%|▎                                          | 2/326 [00:06<17:36,  3.26s/it]\u001b[A\n",
      "  1%|▍                                          | 3/326 [00:12<23:06,  4.29s/it]\u001b[A\n",
      "  0%|                                                     | 0/1 [00:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m model_densenet161\u001b[38;5;241m.\u001b[39mclassifier \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(model_densenet161\u001b[38;5;241m.\u001b[39mclassifier\u001b[38;5;241m.\u001b[39min_features, out_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      7\u001b[0m model_densenet161 \u001b[38;5;241m=\u001b[39m model_densenet161\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> 9\u001b[0m densenet161_training_results \u001b[38;5;241m=\u001b[39m training(model\u001b[38;5;241m=\u001b[39mmodel_densenet161,\n\u001b[1;32m     10\u001b[0m                                         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDenseNet161\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                                         num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs,\n\u001b[1;32m     12\u001b[0m                                         train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[1;32m     13\u001b[0m                                         val_dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader)\n\u001b[1;32m     15\u001b[0m model_densenet161, train_loss_array, train_acc_array, val_loss_array, val_acc_array \u001b[38;5;241m=\u001b[39m densenet161_training_results\n\u001b[1;32m     17\u001b[0m min_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(val_loss_array)\n",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, model_name, num_epochs, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m     29\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(samples)\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, targets)\n\u001b[1;32m     34\u001b[0m preds \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/models/densenet.py:213\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 213\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[1;32m    214\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(features, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    215\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(out, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/models/densenet.py:122\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    120\u001b[0m features \u001b[38;5;241m=\u001b[39m [init_features]\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 122\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m layer(features)\n\u001b[1;32m    123\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(new_features)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(features, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/models/densenet.py:88\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     86\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_checkpoint_bottleneck(prev_features)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_function(prev_features)\n\u001b[1;32m     90\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(bottleneck_output)))\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/models/densenet.py:49\u001b[0m, in \u001b[0;36m_DenseLayer.bn_function\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbn_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     48\u001b[0m     concated_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(inputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(concated_features)))  \u001b[38;5;66;03m# noqa: T484\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bottleneck_output\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "model_densenet161 = models.densenet161(pretrained=True)\n",
    "for param in model_densenet161.parameters():\n",
    "    param.requires_grad = False\n",
    "model_densenet161.classifier = torch.nn.Linear(model_densenet161.classifier.in_features, out_features=2)\n",
    "model_densenet161 = model_densenet161.to(DEVICE)\n",
    "\n",
    "densenet161_training_results = training(model=model_densenet161,\n",
    "                                        model_name='DenseNet161',\n",
    "                                        num_epochs=num_epochs,\n",
    "                                        train_dataloader=train_dataloader,\n",
    "                                        val_dataloader=test_dataloader)\n",
    "\n",
    "model_densenet161, train_loss_array, train_acc_array, val_loss_array, val_acc_array = densenet161_training_results\n",
    "\n",
    "min_loss = min(val_loss_array)\n",
    "min_loss_epoch = val_loss_array.index(min_loss)\n",
    "min_loss_accuracy = val_acc_array[min_loss_epoch]\n",
    "\n",
    "visualize_training_results(train_loss_array,\n",
    "                           val_loss_array,\n",
    "                           train_acc_array,\n",
    "                           val_acc_array,\n",
    "                           num_epochs,\n",
    "                           model_name=\"DenseNet161\",\n",
    "                           batch_size=64)\n",
    "print(\"\\nTraining results:\")\n",
    "print(\"\\tMin val loss {:.4f} was achieved during epoch #{}\".format(min_loss, min_loss_epoch + 1))\n",
    "print(\"\\tVal accuracy during min val loss is {:.4f}\".format(min_loss_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141fb5c1-d736-482c-9d14-3c43a933367c",
   "metadata": {},
   "source": [
    "## Resnet 152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e10d500-1548-408a-9c86-e073aad2c6d4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Learning rate: [0.0003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                   | 0/326 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▏                                          | 1/326 [00:03<17:14,  3.18s/it]\u001b[A\n",
      "  1%|▎                                          | 2/326 [00:08<23:57,  4.44s/it]\u001b[A\n",
      "  0%|                                                     | 0/1 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model_resnet152\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(model_resnet152\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39min_features, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      5\u001b[0m model_resnet152 \u001b[38;5;241m=\u001b[39m model_resnet152\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> 7\u001b[0m resnet152_training_results \u001b[38;5;241m=\u001b[39m training(model\u001b[38;5;241m=\u001b[39mmodel_resnet152,\n\u001b[1;32m      8\u001b[0m                                       model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResNet152\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                       num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs,\n\u001b[1;32m     10\u001b[0m                                       train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[1;32m     11\u001b[0m                                       val_dataloader\u001b[38;5;241m=\u001b[39mvalid_dataloader)\n\u001b[1;32m     13\u001b[0m model_resnet152, train_loss_array, train_acc_array, val_loss_array, val_acc_array \u001b[38;5;241m=\u001b[39m resnet152_training_results\n\u001b[1;32m     15\u001b[0m min_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(val_loss_array)\n",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, model_name, num_epochs, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m     29\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(samples)\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, targets)\n\u001b[1;32m     34\u001b[0m preds \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/models/resnet.py:275\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m--> 275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[1;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/models/resnet.py:154\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m    152\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m--> 154\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(out)\n\u001b[1;32m    155\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(out)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_resnet152 = models.resnet152(pretrained=True)\n",
    "for param in model_resnet152.parameters():\n",
    "    param.requires_grad = False\n",
    "model_resnet152.fc = torch.nn.Linear(model_resnet152.fc.in_features, 2)\n",
    "model_resnet152 = model_resnet152.to(DEVICE)\n",
    "\n",
    "resnet152_training_results = training(model=model_resnet152,\n",
    "                                      model_name='ResNet152',\n",
    "                                      num_epochs=num_epochs,\n",
    "                                      train_dataloader=train_dataloader,\n",
    "                                      val_dataloader=valid_dataloader)\n",
    "\n",
    "model_resnet152, train_loss_array, train_acc_array, val_loss_array, val_acc_array = resnet152_training_results\n",
    "\n",
    "min_loss = min(val_loss_array)\n",
    "min_loss_epoch = val_loss_array.index(min_loss)\n",
    "min_loss_accuracy = val_acc_array[min_loss_epoch]\n",
    "\n",
    "visualize_training_results(train_loss_array,\n",
    "                           val_loss_array,\n",
    "                           train_acc_array,\n",
    "                           val_acc_array,\n",
    "                           num_epochs,\n",
    "                           model_name=\"ResNet152\",\n",
    "                           batch_size=64)\n",
    "print(\"\\nTraining results:\")\n",
    "print(\"\\tMin val loss {:.4f} was achieved during epoch #{}\".format(min_loss, min_loss_epoch + 1))\n",
    "print(\"\\tVal accuracy during min val loss is {:.4f}\".format(min_loss_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db33b6b3-6c31-4e2d-a640-654f67e9d5d8",
   "metadata": {},
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0025a0eb-7d07-40af-a55a-0d9d335a3226",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Learning rate: [0.0003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                   | 0/326 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▏                                          | 1/326 [00:09<50:03,  9.24s/it]\u001b[A\n",
      "  0%|                                                     | 0/1 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model_vgg19_bn\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(in_features\u001b[38;5;241m=\u001b[39mmodel_vgg19_bn\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m6\u001b[39m]\u001b[38;5;241m.\u001b[39min_features, out_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      5\u001b[0m model_vgg19_bn \u001b[38;5;241m=\u001b[39m model_vgg19_bn\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> 7\u001b[0m vgg19_bn_training_results \u001b[38;5;241m=\u001b[39m training(model\u001b[38;5;241m=\u001b[39mmodel_vgg19_bn,\n\u001b[1;32m      8\u001b[0m                                      model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVGG19_bn\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                      num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs,\n\u001b[1;32m     10\u001b[0m                                      train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[1;32m     11\u001b[0m                                      val_dataloader\u001b[38;5;241m=\u001b[39mvalid_dataloader)\n\u001b[1;32m     13\u001b[0m model_vgg19_bn, train_loss_array, train_acc_array, val_loss_array, val_acc_array \u001b[38;5;241m=\u001b[39m vgg19_bn_training_results\n\u001b[1;32m     15\u001b[0m min_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(val_loss_array)\n",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, model_name, num_epochs, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m     29\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(samples)\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, targets)\n\u001b[1;32m     34\u001b[0m preds \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/models/vgg.py:66\u001b[0m, in \u001b[0;36mVGG.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 66\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[1;32m     67\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m     68\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_vgg19_bn = models.vgg19_bn(pretrained=True)\n",
    "for param in model_vgg19_bn.parameters():\n",
    "    param.requires_grad = False\n",
    "model_vgg19_bn.classifier[6] = torch.nn.Linear(in_features=model_vgg19_bn.classifier[6].in_features, out_features=2)\n",
    "model_vgg19_bn = model_vgg19_bn.to(DEVICE)\n",
    "\n",
    "vgg19_bn_training_results = training(model=model_vgg19_bn,\n",
    "                                     model_name='VGG19_bn',\n",
    "                                     num_epochs=num_epochs,\n",
    "                                     train_dataloader=train_dataloader,\n",
    "                                     val_dataloader=valid_dataloader)\n",
    "\n",
    "model_vgg19_bn, train_loss_array, train_acc_array, val_loss_array, val_acc_array = vgg19_bn_training_results\n",
    "\n",
    "min_loss = min(val_loss_array)\n",
    "min_loss_epoch = val_loss_array.index(min_loss)\n",
    "min_loss_accuracy = val_acc_array[min_loss_epoch]\n",
    "\n",
    "visualize_training_results(train_loss_array,\n",
    "                           val_loss_array,\n",
    "                           train_acc_array,\n",
    "                           val_acc_array,\n",
    "                           num_epochs,\n",
    "                           model_name=\"VGG19_bn\",\n",
    "                           batch_size=64)\n",
    "print(\"\\nTraining results:\")\n",
    "print(\"\\tMin val loss {:.4f} was achieved during epoch #{}\".format(min_loss, min_loss_epoch + 1))\n",
    "print(\"\\tVal accuracy during min val loss is {:.4f}\".format(min_loss_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fbae0d-7846-44de-a2cc-603a63ddc293",
   "metadata": {},
   "source": [
    "## Training ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a5e377e-9294-4b51-b5cb-17ce50e99c75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):   \n",
    "    def __init__(self, modelA, modelB, modelC):\n",
    "        super().__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        self.modelC = modelC\n",
    "        self.classifier = nn.Linear(2 * 3, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.modelA(x)\n",
    "        x2 = self.modelB(x)\n",
    "        x3 = self.modelC(x)\n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "        out = self.classifier(x)\n",
    "        return out\n",
    "    \n",
    "ensemble_model = EnsembleModel(model_densenet161, model_resnet152, model_vgg19_bn)\n",
    "\n",
    "for param in ensemble_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in ensemble_model.classifier.parameters():\n",
    "    param.requires_grad = True    \n",
    "\n",
    "ensemble_model = ensemble_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e7a34bd-95c5-4878-856f-7a88d66f998c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Learning rate: [0.0003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                   | 0/326 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▏                                          | 1/326 [00:09<54:04,  9.98s/it]\u001b[A\n",
      "  1%|▎                                        | 2/326 [00:30<1:23:08, 15.40s/it]\u001b[A\n",
      "  0%|                                                     | 0/1 [00:30<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ensemble_training_results \u001b[38;5;241m=\u001b[39m training(model\u001b[38;5;241m=\u001b[39mensemble_model,\n\u001b[1;32m      2\u001b[0m                                      model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnsemble\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                      num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs,\n\u001b[1;32m      4\u001b[0m                                      train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[1;32m      5\u001b[0m                                      val_dataloader\u001b[38;5;241m=\u001b[39mvalid_dataloader)\n\u001b[1;32m      7\u001b[0m ensemble_model, train_loss_array, train_acc_array, val_loss_array, val_acc_array \u001b[38;5;241m=\u001b[39m ensemble_training_results\n\u001b[1;32m      9\u001b[0m min_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(val_loss_array)\n",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, model_name, num_epochs, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m     29\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(samples)\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, targets)\n\u001b[1;32m     34\u001b[0m preds \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m, in \u001b[0;36mEnsembleModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodelA(x)\n\u001b[1;32m     11\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodelB(x)\n\u001b[0;32m---> 12\u001b[0m x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodelC(x)\n\u001b[1;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x1, x2, x3), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/models/vgg.py:66\u001b[0m, in \u001b[0;36mVGG.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 66\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[1;32m     67\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m     68\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ensemble_training_results = training(model=ensemble_model,\n",
    "                                     model_name='Ensemble',\n",
    "                                     num_epochs=num_epochs,\n",
    "                                     train_dataloader=train_dataloader,\n",
    "                                     val_dataloader=valid_dataloader)\n",
    "\n",
    "ensemble_model, train_loss_array, train_acc_array, val_loss_array, val_acc_array = ensemble_training_results\n",
    "\n",
    "min_loss = min(val_loss_array)\n",
    "min_loss_iteration = val_loss_array.index(min_loss)\n",
    "min_loss_accuracy = val_acc_array[min_loss_iteration]\n",
    "\n",
    "visualize_training_results(train_loss_array,\n",
    "                           val_loss_array,\n",
    "                           train_acc_array,\n",
    "                           val_acc_array,\n",
    "                           num_epochs=num_epochs,\n",
    "                           model_name=\"Ensemble model\",\n",
    "                           batch_size=64)\n",
    "print(\"\\nTraining results:\")\n",
    "print(\"\\tMin val loss {:.4f} was achieved during iteration #{}\".format(min_loss, min_loss_iteration + 1))\n",
    "print(\"\\tVal accuracy during min val loss is {:.4f}\".format(min_loss_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c393b-7294-4bda-bc8e-9163c09ba5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
